\section{Camera Theory}
An image captured through a camera is the result of reflected light being detected on a camera sensor, see figure \ref{fig:light_cam}. This process is know as \textit{image acquisition} and is generally not something you think about when you capture an image with a camera, since it all happens automatically. In this chapter the basics of image acquisition using a digital camera will be explained. To understand how this works it is necessary to have a basic understanding of the physics behind light.

\begin{figure}[htbp] 
\centering 
\includegraphics[width=0.5\textwidth]{Pictures/Theory/light_from_sun.png} 
\caption{Light as captured by a camera} 
\label{fig:light_cam} 
\end{figure}

Light is a form of electromagnetic radiation and can be viewed as both waves and particles. This duality is however not something that will be concerned within this chapter; the wave model is sufficient to build the foundation of the understanding we need. A light wave is a small packet of energy traveling through space. These energy packets are known as photons. Photons can be described by three properties:

\begin{itemize}
\item \textbf{Wavelenght} - Measured in meters from wave top to wave top and denoted as $\lambda$.
\item \textbf{Frequency} - Measured in oscillations per second, Hz, denoted $f$.
\item \textbf{Energy} - Measured in electronvolts, eV, denoted $E$.
\end{itemize}

The formulae for these properties are as follows:
To derive the wavelength or the frequency, formula \ref{eq:wavelenght} is applied:
\begin{align}
\centering 
\lambda = \frac{C}{f}
\label{eq:wavelenght} 
\end{align}
$\lambda$ and f we are familiar with, and C is the speed of light. The second equation, equation \ref{eq:e_v}, describes the energy:
\begin{align}
\centering
E = \frac{hC}{\lambda}
\label{eq:e_v} 
\end{align}
where h is Planck's constant, which describes the proportional relationship between energy of a photon and an the corresponding electromagnetic wave's frequency. E, C and $\lambda$ are still as explained above.

The wavelength of the photon determines what color one perceives. However; as we know from physics, the speed of light is constant; thus changing the frequency will alter the wavelength and therefore the color that is perceived. The visible spectrum of light is but a fraction of the full spectrum of electromagnetic radiation \fixme{SEE THE FIGURE THAT IS NOT THERE}. As with images, light interacts additively, with a mix of equal parts of each wavelength resulting in white light.
\fixme{image of light color by wavelength}
The most common light source by far is the sun. The white light from the sun can be broken down into its component wavelengths by refracting the light in a prism. This will yield the full color spectrum\fixme{MORE PICTURES; LIGHT REFRACTED}.
While different wavelengths correspond to different colors, these colors only remain defined within our perception. The reason we see ~600nm light as yellow is because our eyes contain three types of optically sensitive cells, known as \textit{cones}, constructed to be sensitive to three colors; red, green and blue. 600 nm lies between the green and red cells, thus both cells are firing and the perceived color becomes yellow.\citep{perception_book}.\fixme{link to cells and visible spectrum maybe figures?}
\subsection{Digital image acquisition}
When capturing an image using a digital camera, light is passed through a lens onto the sensor, which acts in much the same way as our eyes. In place of cones sensitive to specific wavelengths, a camera sensor has a physical matrix of pixel sensors, one for each pixel in the output image. A camera that can only capture black and white photos have only one type of sensor in each physical pixel whereas a camera that captures RGB color images has three types of sensors in each pixel. \fixme{sources and images?}
\subsection{Image acquisition in the project}
In the project, two cameras were contemplated; a normal RGB webcam and a similar camera with an infrared (IR) filter installed. The filter consists of a small strip of normal analogue film, used for analogue pictures, that has been mounted on the lens. The film strip allows only infrared light to pass, thus making the only light that reaches the sensor infrared. 

\begin{figure}[htbp] 
\centering 
\includegraphics[width=0.5\textwidth]{Pictures/Theory/IR_filter.png} 
\caption{The IR filter only allows infrared ligh to pass} 
\label{fig:ir_filter} 
\end{figure}

This is interesting, as it enables a larger degree of control over the illumination in the scene that is captured. Normally in a scene, controlling the lighting  \fixme{should be refenrence to place where we state that light is hard to control and the issues inherit in handling lighting "on location"} can prove a challenge, and in order to operate without error an image processing algorithm would have to take into account the variance in lighting that occurs naturally during a day cycle. Working with IR eliminates this issue.

\subsection{Illuminating the scene}

For many different image processing procedures it important that the lightning in the scene is constant. Imagine that the scene is captured with a normal webcam, this creates an RGB image, \ref{fig:scene_light}.  In this case, we want to find the shelves, so we can place virtual objects in them for our imaginary augmented reality program. In order to speed things up, the image is converted to grayscale, as part of the  image processing, an algorithm thresholds the image, discarding all pixels with values less than 113. In the right picture the program can easily find the shelves, but in the picture on the left, the program cannot find the shelves, see \ref{fig:scene_thresholded}.

\begin{figure}[htbp] 
\centering 
\includegraphics[width=0.5\textwidth]{Pictures/HjoerringLibrary/scene_lighting.png} 
\caption{The difference in illumination on different times of day is clearly visible when compared next to each other} 
\label{fig:scene_light} 
\end{figure}

\begin{figure}[htbp] 
\centering 
\includegraphics[width=0.5\textwidth]{Pictures/HjoerringLibrary/scene_lighting_thresholded.png} 
\caption{The same image converted to 8bit grayscale and thresholded.} 
\label{fig:scene_thresholded} 
\end{figure}

To avoid running into issues with variances in illumination, the descision was quickly made to illuminate the scene artificially. Different options were evaluated for the illumination, all under the consideration that we had the ability to filter the camera input, allowing only IR-light to pass to the camera. The following options were considered:

\begin{itemize}
\item Using the normal lighting at the library.
\item Making adjustments to the lighting at the library.
\item 
\end{itemize}